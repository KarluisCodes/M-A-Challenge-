{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4745cea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aab8867c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL of the PSE Edge company directory\n",
    "base_url = \"https://edge.pse.com.ph/companyDirectory/search.ax\"\n",
    "\n",
    "# Empty list to hold results\n",
    "all_data = []\n",
    "\n",
    "# Get data from all pages\n",
    "for page in range(1, 7):\n",
    "    payload = {\n",
    "        'pageNo': page,\n",
    "        'keyword': '',\n",
    "        'sortType': '',\n",
    "        'dateSortType': 'DESC',\n",
    "        'cmpySortType': 'ASC',\n",
    "        'symbolSortType': 'ASC',\n",
    "        'sector': 'ALL',\n",
    "        'subsector': ''\n",
    "    }\n",
    "    \n",
    "    # Send POST request (the site loads data via AJAX)\n",
    "    response = requests.post(base_url, data=payload)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Find all company rows inside the main table\n",
    "    rows = soup.select('table.list tbody tr')\n",
    "    \n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        if len(cols) == 5:\n",
    "            company_name = cols[0].text.strip()\n",
    "            stock_symbol = cols[1].text.strip()\n",
    "            sector = cols[2].text.strip()\n",
    "            subsector = cols[3].text.strip()\n",
    "            listing_date = cols[4].text.strip()\n",
    "            \n",
    "            all_data.append({\n",
    "                \"Company Name\": company_name,\n",
    "                \"Stock Symbol\": stock_symbol,\n",
    "                \"Sector\": sector,\n",
    "                \"Subsector\": subsector\n",
    "            })\n",
    "    \n",
    "    # Take break from requests\n",
    "    time.sleep(1)\n",
    "\n",
    "# Convert to df\n",
    "df_pse = pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ff4f54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your target sectors and subsectors\n",
    "target_sectors = [\n",
    "    \"Industrial\",\n",
    "    \"Holding Firms\"\n",
    "]\n",
    "\n",
    "target_subsectors = [\n",
    "    \"Electricity, Energy, Power, & Water\",\n",
    "    \"Construction, Infra. & Allied Services\",\n",
    "    \"Holding Firms\"\n",
    "]\n",
    "\n",
    "# Filter df_pse where either Sector or Subsector matches\n",
    "df_pse_final = df_pse[\n",
    "    (df_pse['Sector'].isin(target_sectors)) |\n",
    "    (df_pse['Subsector'].isin(target_subsectors))\n",
    "].copy()\n",
    "\n",
    "# Reset index for cleanliness\n",
    "df_pse_final.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_pse_final = df_pse_final[['Company Name', 'Stock Symbol']]\n",
    "\n",
    "df_pse_final.to_csv('filtered_pse_companies.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50144b0f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d361007d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_companies = pd.read_csv(\"filtered_pse_companies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "256ccd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping ACEN CORPORATION (ACEN)...\n",
      "  Searching for ACEN...\n",
      "  Found ACEN: company_id=233\n",
      "  Fetching financial reports for ACEN...\n",
      "  No financial data available for ACEN\n",
      "✗ No financial data available for ACEN\n",
      "Scraping Ayala Corporation (AC)...\n",
      "  Searching for AC...\n",
      "  Found AC: company_id=57\n",
      "  Fetching financial reports for AC...\n",
      "  No financial data available for AC\n",
      "✗ No financial data available for AC\n",
      "Scraping Manila Electric Company (MER)...\n",
      "  Searching for MER...\n",
      "  Found MER: company_id=118\n",
      "  Fetching financial reports for MER...\n",
      "  No financial data available for MER\n",
      "✗ No financial data available for MER\n",
      "Scraping BDO Unibank, Inc. (BDO)...\n",
      "  Searching for BDO...\n",
      "  Found BDO: company_id=260\n",
      "  Fetching financial reports for BDO...\n",
      "  No financial data available for BDO\n",
      "✗ No financial data available for BDO\n"
     ]
    }
   ],
   "source": [
    "class PSEEdgeScraper:\n",
    "    def __init__(self):\n",
    "        self.base_url = \"https://edge.pse.com.ph\"\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        })\n",
    "        # Selenium setup\n",
    "        options = Options()\n",
    "        options.headless = True\n",
    "        options.add_argument(\"--disable-gpu\")\n",
    "        options.add_argument(\"--no-sandbox\")\n",
    "        self.driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    def get_company_ids(self, symbol):\n",
    "        \"\"\"Get company_id and security_id with multiple search methods\"\"\"\n",
    "        try:\n",
    "            print(f\"  Searching for {symbol}...\")\n",
    "            search_url = f\"{self.base_url}/autoComplete/searchCompanyNameSymbol.ax\"\n",
    "            params = {'term': symbol}\n",
    "            response = self.session.get(search_url, params=params)\n",
    "            if response.status_code == 200:\n",
    "                companies = response.json()\n",
    "                for company in companies:\n",
    "                    if company.get('symbol') == symbol:\n",
    "                        print(f\"  Found {symbol}: company_id={company.get('cmpyId')}\")\n",
    "                        return company.get('cmpyId'), company.get('securityId')\n",
    "\n",
    "            print(f\"  Trying directory search for {symbol}...\")\n",
    "            for page in range(1, 10):\n",
    "                directory_url = f\"{self.base_url}/companyDirectory/search.ax\"\n",
    "                data = {\n",
    "                    'pageNo': str(page),\n",
    "                    'keyword': symbol,\n",
    "                    'sector': 'ALL',\n",
    "                    'subsector': 'ALL'\n",
    "                }\n",
    "                response = self.session.post(directory_url, data=data)\n",
    "                if response.status_code == 200:\n",
    "                    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "                    company_links = soup.find_all('a', string=symbol)\n",
    "                    for link in company_links:\n",
    "                        onclick = link.get('onclick', '')\n",
    "                        match = re.search(r\"cmDetail\\('(\\d+)','(\\d+)'\\)\", onclick)\n",
    "                        if match:\n",
    "                            company_id = match.group(1)\n",
    "                            security_id = match.group(2)\n",
    "                            print(f\"  Found {symbol} on page {page}: company_id={company_id}, security_id={security_id}\")\n",
    "                            return company_id, security_id\n",
    "            print(f\"  Could not find {symbol} in directory\")\n",
    "            return None, None\n",
    "        except Exception as e:\n",
    "            print(f\"  Error getting company IDs for {symbol}: {e}\")\n",
    "            return None, None\n",
    "\n",
    "    def get_financial_reports(self, company_id, symbol, company_name):\n",
    "        \"\"\"Get financial reports using Selenium\"\"\"\n",
    "        try:\n",
    "            print(f\"  Fetching financial reports for {symbol}...\")\n",
    "            url = f\"{self.base_url}/companyPage/financial_reports_view.do?cmpy_id={company_id}\"\n",
    "            self.driver.get(url)\n",
    "\n",
    "            # Wait for the first Balance Sheet table to appear (max 15s)\n",
    "            try:\n",
    "                WebDriverWait(self.driver, 15).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, \"//table[caption[text()='Balance Sheet']]\"))\n",
    "                )\n",
    "            except:\n",
    "                print(f\"  Table did not load for {symbol}\")\n",
    "                return None\n",
    "\n",
    "            soup = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "\n",
    "            # Check for no data message\n",
    "            no_data_msg = soup.find('p', class_='textCont')\n",
    "            if no_data_msg and \"will become available upon submission\" in no_data_msg.text:\n",
    "                print(f\"  No financial data available for {symbol}\")\n",
    "                return None\n",
    "\n",
    "            financial_data = {\n",
    "                'Symbol': symbol,\n",
    "                'Company_Name': company_name,\n",
    "                'Company_ID': company_id,\n",
    "                'Scraped_Date': datetime.now().strftime('%Y-%m-%d')\n",
    "            }\n",
    "\n",
    "            # Parse tables\n",
    "            for table in soup.find_all('table', class_='view'):\n",
    "                caption = table.find('caption')\n",
    "                if caption:\n",
    "                    if 'Balance Sheet' in caption.text:\n",
    "                        financial_data.update(self.parse_financial_table(table, 'Annual_BS'))\n",
    "                    elif 'Income Statement' in caption.text:\n",
    "                        financial_data.update(self.parse_financial_table(table, 'Annual_IS'))\n",
    "\n",
    "            data_keys = [k for k in financial_data.keys() if k not in ['Symbol','Company_Name','Company_ID','Scraped_Date']]\n",
    "            if not data_keys:\n",
    "                print(f\"  No financial data extracted for {symbol}\")\n",
    "                return None\n",
    "\n",
    "            print(f\"  Successfully extracted {len(data_keys)} data points for {symbol}\")\n",
    "            return financial_data\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  Error getting financial reports for {symbol}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def parse_financial_table(self, table, prefix):\n",
    "        \"\"\"Parse Balance Sheet or Income Statement table into dictionary\"\"\"\n",
    "        data = {}\n",
    "        try:\n",
    "            rows = table.find_all('tr')\n",
    "            for row in rows[1:]:\n",
    "                cells = row.find_all(['th','td'])\n",
    "                if len(cells) >= 3:\n",
    "                    item_name = cells[0].get_text(strip=True)\n",
    "                    current_val = cells[1].get_text(strip=True)\n",
    "                    previous_val = cells[2].get_text(strip=True)\n",
    "\n",
    "                    col_name = re.sub(r\"[^\\w\\s]\", \"\", item_name).replace(\" \",\"_\")\n",
    "\n",
    "                    def parse_num(val):\n",
    "                        val = val.replace(\",\",\"\")\n",
    "                        try:\n",
    "                            return float(val)\n",
    "                        except:\n",
    "                            return None\n",
    "\n",
    "                    if current_val and current_val != '-':\n",
    "                        data[f\"{prefix}_{col_name}_Current\"] = parse_num(current_val)\n",
    "                    if previous_val and previous_val != '-':\n",
    "                        data[f\"{prefix}_{col_name}_Previous\"] = parse_num(previous_val)\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing table: {e}\")\n",
    "            return data\n",
    "\n",
    "    def scrape_all_companies(self, df_companies):\n",
    "        all_financials = []\n",
    "        for index, row in df_companies.iterrows():\n",
    "            symbol = row['Stock Symbol']\n",
    "            company_name = row['Company Name']\n",
    "            print(f\"Scraping {company_name} ({symbol})...\")\n",
    "            company_id, security_id = self.get_company_ids(symbol)\n",
    "            if company_id:\n",
    "                financial_data = self.get_financial_reports(company_id, symbol, company_name)\n",
    "                if financial_data:\n",
    "                    all_financials.append(financial_data)\n",
    "                    print(f\"✓ Successfully scraped {symbol}\")\n",
    "                else:\n",
    "                    print(f\"✗ No financial data available for {symbol}\")\n",
    "            else:\n",
    "                print(f\"✗ Could not find company IDs for {symbol}\")\n",
    "            time.sleep(2)\n",
    "        return pd.DataFrame(all_financials)\n",
    "\n",
    "# --- Test the scraper ---\n",
    "if __name__ == \"__main__\":\n",
    "    test_companies = pd.DataFrame({\n",
    "        'Company Name': ['ACEN CORPORATION','Ayala Corporation','Manila Electric Company','BDO Unibank, Inc.'],\n",
    "        'Stock Symbol': ['ACEN','AC','MER','BDO']\n",
    "    })\n",
    "    scraper = PSEEdgeScraper()\n",
    "    df = scraper.scrape_all_companies(test_companies)\n",
    "    if not df.empty:\n",
    "        print(df.head())\n",
    "        df.to_csv('pse_financial_data.csv', index=False)\n",
    "        print(\"Saved to pse_financial_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
